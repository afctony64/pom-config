# =============================================================================
# SHARED CONFIGURATION (Non-Secrets)
# =============================================================================
#
# This file is part of pom-config and is shared across all Pom ecosystem apps.
# Update via: ./scripts/pom_config.sh update
#
# For secrets (API keys, passwords), use ~/.shared-credentials.env instead.
#
# See: pom-docs/docs/infrastructure/SHARED_CONFIG_GUIDE.md
#
# =============================================================================

# =============================================================================
# SERVICE PORTS (Single Source of Truth)
# =============================================================================
# These ports are the canonical assignments for all Pom ecosystem services.
# Docker Compose files should reference these variables.
# See also: pom-config/services.yaml for full service definitions.

# ----- Frontends -----
POMOTHY_FRONTEND_PORT=5174
POMAI_FRONTEND_PORT=5173
REPORT_SERVER_PORT=8886

# ----- Backends -----
POMOTHY_BACKEND_PORT=8001
LLM_PROXY_EXTERNAL_PORT=4001
LLM_PROXY_INTERNAL_PORT=8000

# ----- Databases -----
WEAVIATE_PORT=8080
WEAVIATE_GRPC_PORT=50051
REDIS_PORT=6379

# ----- AI Services -----
OLLAMA_LB_PORT=11430
MAC_OLLAMA_NATIVE_PORT=11435
MAC_TRANSFORMERS_NATIVE_PORT=8093

# ----- Supabase -----
SUPABASE_STUDIO_PORT=3100
SUPABASE_KONG_PORT=8100
SUPABASE_DB_PORT=5432

# ----- Observability -----
LOKI_PORT=3102
TEMPO_PORT=3200
JAEGER_UI_PORT=16686

# ----- Dev Tools -----
REDIS_INSIGHT_PORT=5540
MINIO_API_PORT=9000
MINIO_CONSOLE_PORT=9001
MAILHOG_UI_PORT=8025

# ----- Reserved Ports (DO NOT USE) -----
# 4000 - Cursor MCP Server (CRITICAL - will conflict!)
# 5000 - macOS ControlCenter / AirPlay
# 3000 - Common dev server default (React, Next.js)

# =============================================================================
# RUNTIME DEFAULTS (Applied on fresh startup/recreate)
# =============================================================================
# These are the CANONICAL defaults. Individual services should NOT override.
# See pom-config/runtime.yaml for full configuration.

# Default mode on startup (home = Mac + Spark)
DEFAULT_MODE=home

# Default workload profile on startup (data_pipeline = heavy embeddings)
DEFAULT_WORKLOAD_PROFILE=data_pipeline

# Validate configuration after mode/profile switch
VALIDATE_ON_SWITCH=true

# Require validation to pass before considering switch complete
REQUIRE_VALIDATION=true

# Auto-recover to home mode on container restart (if in travel/ooo)
AUTO_RECOVERY_TO_HOME=true

# =============================================================================
# SYSTEM PATHS
# =============================================================================

# Researcher seed data directory (used by pom-core seed loading)
RESEARCHER_SEED_OUTPUT_DIR=/app/PomAI/Data/seeds

# Shared reports directory (centralized reports outside all repos)
# Mac: /Users/tonyeales/Projects/shared-reports
# Spark (container): /shared-reports
SHARED_REPORTS_PATH=/Users/tonyeales/Projects/shared-reports

# Spark shared reports directory (host path)
SPARK_SHARED_REPORTS_PATH=/home/afctony64/Projects/shared-reports

# PomAI reports sync hook (Mac report server on-access sync)
POMAI_REPORTS_SYNC_PORT=8877
POMAI_REPORTS_SYNC_COOLDOWN_SECONDS=120
POMAI_REPORTS_SYNC_TIMEOUT_SECONDS=120

# pom-config shared configuration root
POM_CONFIG_ROOT=/app/shared_config

# =============================================================================
# SYSTEM BEHAVIOR
# =============================================================================
# Note: DEFAULT_MODE, DEFAULT_WORKLOAD_PROFILE, VALIDATE_ON_SWITCH are in
# RUNTIME DEFAULTS section above (line ~65)

# PomSpark infrastructure mode (current active mode)
# Options: home (Mac + Spark), travel (Mac only), ooo (Spark unattended)
POMSPARK_MODE=home

# Weaviate mode (which Weaviate instance to use)
# Options: spark (local Spark Weaviate), cloud (Weaviate Cloud), local (Mac Weaviate)
WEAVIATE_MODE=spark

# Default log level for all services
# Use WARNING for normal operation, DEBUG for troubleshooting system internals
LOG_LEVEL=WARNING

# NOTE: File logging removed - all logs go to stdout for docker logs
# Promtail scrapes Docker logs and sends to Loki for dashboards

# =============================================================================
# WEAVIATE CONFIGURATION
# =============================================================================
# Tenant/Collection Routing: Both Mac and Spark workspaces need access to
# tenant instances across both Weaviate instances. Routing is controlled by
# pom-core based on tenant/collection configuration.

# Primary Weaviate URL (based on current mode)
# Note: Use spark-65d6.local for cross-network accessibility
WEAVIATE_URL=http://spark-65d6.local:8080

# Mac Weaviate (local Docker network)
MAC_WEAVIATE_URL=http://mac-weaviate:8080

# Spark Weaviate URLs (with fallback priority)
# Priority 1: Local network (spark-65d6.local) - fastest, same network
# Priority 2: DigitalOcean proxy - remote access when not on same network
# Note: Mac containers cannot resolve Docker hostnames on Spark server's network
SPARK_WEAVIATE_URL=http://spark-65d6.local:8080
SPARK_WEAVIATE_URL_FALLBACK=http://spark-proxy.digitalocean.com:8080

# Spark Weaviate via DigitalOcean Proxy (remote access fallback)
# Used when Mac is not on same network as Spark (travel mode, remote work)
SPARK_WEAVIATE_PROXY_URL=http://spark-proxy.digitalocean.com:8080

# Weaviate Cloud
WEAVIATE_CLOUD_URL=https://ewkhvwtiswgp8ugywr8sma.c0.us-east1.gcp.weaviate.cloud
DEFAULT_WEAVIATE_TARGET=cloud

# gRPC (with fallback)
WEAVIATE_GRPC_URL=spark-65d6.local:50051
SPARK_WEAVIATE_GRPC_URL=spark-65d6.local:50051
SPARK_WEAVIATE_GRPC_PROXY_URL=spark-proxy.digitalocean.com:50051

# =============================================================================
# OLLAMA CONFIGURATION (LLM Inference)
# =============================================================================

# Primary Ollama URL (based on current mode)
OLLAMA_URL=http://spark-ollama:11434
OLLAMA_BASE_URL=http://host.docker.internal:11430

# Mac native Ollama
MAC_OLLAMA_URL=http://host.docker.internal:11435

# Spark Ollama URLs (with fallback priority)
# Priority 1: Local network (spark-65d6.local) - fastest, same network
# Priority 2: DigitalOcean proxy - remote access when not on same network
SPARK_OLLAMA_URL=http://spark-65d6.local:11434
SPARK_OLLAMA_PROXY_URL=http://spark-proxy.digitalocean.com:11434

# Ollama Load Balancer
OLLAMA_LB_URL=http://host.docker.internal:11430

# Fallback URLs for reliability
OLLAMA_FALLBACK_URLS=http://host.docker.internal:11435,http://spark-65d6.local:11434

# Timeouts (seconds)
OLLAMA_TIMEOUT=900
LLM_PROXY_PROCESSING_TIMEOUT=900

# =============================================================================
# TRANSFORMERS CONFIGURATION (Embeddings)
# =============================================================================

# Primary Transformers URL (based on current mode)
TRANSFORMERS_URL=http://spark-transformers-lb:80

# Mac Metal transformers
MAC_TRANSFORMERS_URL=http://host.docker.internal:8093

# Spark transformers load balancer URLs (with fallback priority)
# Priority 1: Local network (spark-65d6.local:8090) - fastest, same network
# Priority 2: DigitalOcean proxy - remote access when not on same network
SPARK_TRANSFORMERS_URL=http://spark-65d6.local:8090
SPARK_TRANSFORMERS_PROXY_URL=http://spark-proxy.digitalocean.com:8090

# =============================================================================
# TOOLING CONFIGURATION
# =============================================================================

SETUPTOOLS_SCM_PRETEND_VERSION=5.1.88

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================

REDIS_URL=redis://mac-redis:6379

# =============================================================================
# SUPABASE CONFIGURATION (URLs only - keys in shared-credentials.env)
# =============================================================================

SUPABASE_URL=https://mhgpujddrrxwlfoyegxg.supabase.co

# =============================================================================
# FRONTEND CONFIGURATION (VITE)
# =============================================================================

VITE_API_BASE_URL=http://localhost:8001
VITE_SERVICE_URL=http://localhost:8001
VITE_WS_URL=ws://localhost:8001
VITE_BACKEND_URL=http://localhost:8001
FRONTEND_URL=http://localhost:5174

# Supabase frontend (anon key in shared-credentials.env)
VITE_SUPABASE_URL=https://mhgpujddrrxwlfoyegxg.supabase.co

# =============================================================================
# GCS BACKUP CONFIGURATION
# =============================================================================

GCS_BACKUP_BUCKET=pomothy-weaviate-backups-gcs
BACKUP_BUCKET=pomothy-weaviate-backups-gcs

# =============================================================================
# VAST.AI CONFIGURATION
# =============================================================================

VAST_ENDPOINT_NAME=vLLM-Qwen3-8B

# =============================================================================
# OMADA CONTROLLER (URLs only - credentials in shared-credentials.env)
# =============================================================================

OMADA_CONTROLLER_URL=https://192.168.0.229
OMADA_SITE=Default

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# SSRF protection (disable only for trusted internal services)
DISABLE_SSRF_PROTECTION=false

# SSL verification for HTTPX client
HTTPX_VERIFY_SSL=true

# URL validation for web scraping
ENABLE_URL_VALIDATION=true

# =============================================================================
# HTTP CLIENT CONFIGURATION
# =============================================================================

# Default timeout for HTTP requests (seconds)
REQUESTS_TIMEOUT=30

# Maximum content size for downloaded pages (bytes)
MAX_CONTENT_SIZE=300000

# ----- aiohttp Connection Pool (Web Scraping) -----
# Total concurrent HTTP connections (aggressive - Spark can handle 262K conntrack)
HTTP_CONNECTION_LIMIT=30000

# Max connections per domain (politeness limit)
HTTP_LIMIT_PER_HOST=10

# Keep idle connections open for reuse (seconds)
HTTP_KEEPALIVE_TIMEOUT=5

# ----- Web Concurrency (Global Semaphores) -----
# Max domains to scrape in parallel (main throughput control)
# - Aligns with browser pool (500) and HTTP pool capacity
WEB_CONCURRENT_DOMAINS=500

# Max concurrent requests per domain (politeness)
WEB_PER_DOMAIN_MAX_CONCURRENT=5

# ----- Gateway NAT Protection -----
# Max unique destination hosts to protect Cox Gateway (~8K NAT limit)
# Set to 6000 for safety margin (75% of gateway capacity)
MAX_UNIQUE_DESTINATIONS=6000

# Enable/disable the gateway protection guard
DESTINATION_GUARD_ENABLED=true

# =============================================================================
# REDIS CONFIGURATION (extended)
# =============================================================================

# Redis database number (0-15)
REDIS_DB=0

# =============================================================================
# BROWSER POOL CONFIGURATION
# =============================================================================

# Number of browser contexts in pool (Spark has 128GB RAM)
# Browser pool size - max concurrent browser contexts
# - Conservative (8GB): 25
# - data_pipeline (48GB): 500 (each context ~100MB with optimizations)
# - Current: 500 (restored after conntrack fix - 5 min timeout prevents network saturation)
BROWSER_POOL_SIZE=500

# Idle timeout before hibernate (seconds)
BROWSER_IDLE_TIMEOUT=300

# Page load timeout (milliseconds)
BROWSER_PAGE_TIMEOUT=90000

# Browser pool URLs
BROWSER_PROXY_URL=http://browser-proxy:80
MAC_BROWSER_POOL_URL=http://mac-browser-pool:4100
SPARK_BROWSER_POOL_URL=http://spark-browser-pool:4100

# =============================================================================
# WEAVIATE TUNING
# =============================================================================

# Enable Weaviate Cloud integration
WEAVIATE_CLOUD_ENABLED=true

# Query defaults
QUERY_DEFAULTS_LIMIT=100
QUERY_MAXIMUM_RESULTS=10000

# Disk usage thresholds (percent)
DISK_USE_WARNING_PERCENTAGE=80
DISK_USE_READONLY_PERCENTAGE=95

# Go runtime tuning (Spark Weaviate - profile-overridable)
# GOMEMLIMIT: Soft memory limit for Go runtime (prevents OOM)
# GOGC: Garbage collection target percentage (lower = more frequent GC)
SPARK_WEAVIATE_GOMEMLIMIT=65GiB
SPARK_WEAVIATE_GOGC=50

# =============================================================================
# PIPELINE OBSERVABILITY (Stale Run Detection)
# =============================================================================
# See: pom-docs/docs/infrastructure/CLI_OBSERVABILITY_ARCHITECTURE.md

# Stale run threshold (seconds) - runs with no heartbeat for this long are stale
# 60 seconds: balances responsiveness with allowing slow operations
# (some CLI operations take >30s per item, causing false-positive stale detection)
STALE_RUN_MAX_AGE=60

# How often the exporter checks for stale runs (seconds)
# REAL-TIME: 15 seconds (was 60) - check frequently for responsive dashboard
STALE_RUN_CLEANUP_INTERVAL=15

# Enable automatic stale run cleanup in the Redis exporter
STALE_RUN_CLEANUP_ENABLED=true

# =============================================================================
# POMFLOW CLI CONFIGURATION
# =============================================================================

# Default max concurrent operations for pomflow CLI
# Overrides model card optimal_concurrency when set
POMFLOW_MAX_CONCURRENT=20

# Default max concurrent operations for standard pom-core CLIs
CLI_MAX_CONCURRENT=100

# =============================================================================
# BRAVE SEARCH CONFIGURATION
# =============================================================================

# Seconds between requests (rate limiting)
BRAVE_RATE_LIMIT=0.1

# Max parallel requests (per instance)
BRAVE_MAX_CONCURRENT=10

# Global semaphore limit for Brave API calls
BRAVE_SEMAPHORE=10

# Default results per query
BRAVE_RESULTS_COUNT=10

# Retry configuration
BRAVE_MAX_RETRIES=3
BRAVE_BACKOFF_FACTOR=2.0

# =============================================================================
# OPENAI HTTPX POOL LIMITS
# =============================================================================

OPENAI_HTTP_MAX_CONNECTIONS=200
OPENAI_HTTP_MAX_KEEPALIVE=200

# =============================================================================
# OLLAMA TUNING (Spark GPU - 128GB RAM)
# =============================================================================

# Concurrent requests per loaded model
# 32 parallel x 2 models = 64 total concurrent requests
OLLAMA_NUM_PARALLEL=32

# Maximum models in RAM (128GB allows 2 large models)
OLLAMA_MAX_LOADED_MODELS=2

# Keep models loaded after last request
OLLAMA_KEEP_ALIVE=1h

# Enable flash attention for memory efficiency
OLLAMA_FLASH_ATTENTION=1

# Maximum queue size for pending requests
OLLAMA_MAX_QUEUE=1000

# =============================================================================
# SPARK SERVER CONFIGURATION (Infrastructure Defaults)
# =============================================================================
# These are the canonical Spark server connection details.
# Scripts should source these instead of hardcoding.

# Spark server hostname (mDNS/Bonjour)
SPARK_HOST=spark-65d6.local

# Spark server IP (fallback when mDNS unavailable)
SPARK_IP=192.168.0.219

# Spark SSH username
SPARK_USER=afctony64

# Spark Tailscale hostname (VPN access)
SPARK_TAILSCALE=spark-65d6

# Spark project paths (on Spark server)
SPARK_POMSPARK_PATH=/home/afctony64/Projects/PomSpark
SPARK_POMAI_PATH=/home/afctony64/Projects/PomAI
SPARK_POMOTHY_PATH=/home/afctony64/Projects/Pomothy

# =============================================================================
# CLOUDFLARE TUNNEL CONFIGURATION (OOO/Remote Access)
# =============================================================================
# These are the Cloudflare tunnel URLs for remote access to services.
# Used in OOO mode and remote development.

# Spark services via Cloudflare tunnel
SPARK_OLLAMA_TUNNEL_URL=https://spark-ollama.pomothy.io
SPARK_WEAVIATE_TUNNEL_URL=https://spark-weaviate.pomothy.io
SPARK_TRANSFORMERS_TUNNEL_URL=https://spark-transformers.pomothy.io

# Cloudflare tunnel names
CLOUDFLARE_TUNNEL_MAC=pom-proxy
CLOUDFLARE_TUNNEL_SPARK=spark-services
CLOUDFLARE_TUNNEL_SPARK_ID=6d4a4972-ec26-4ca3-9df2-59b543b1e45a
