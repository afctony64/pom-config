id: gpt-4o-mini
name: GPT 4o Mini
type: llm_model
version: 1.0.0
provider:
  name: openai
  api_type: chat
adapter_config:
  type: openai_chat
  model: gpt-4o-mini
  base_url: null
  base_url_env: OPENAI_API_KEY
parameters:
  max_tokens: 4096
  temperature: 0.7
capabilities:
  structured_output: json_strict  # OpenAI supports strict JSON schema enforcement
  reasoning: false  # Not a reasoning model - fast chat
  reasoning_summary: false
  tool_calling: true
  streaming: true
  vision: true  # Supports vision
  function_calling: true
cost:
  per_1m_input_tokens: 0.15
  per_1m_output_tokens: 0.6
  currency: USD
performance:
  avg_latency_ms: 400  # Fast - ~400ms TTFT
  tokens_per_second: 100
  context_window: 128000  # 128K context

# Context variants for strategy-aware context management
context_variants:
  throughput: {context_window: 8192}    # Ultra-fast, minimal cost
  balanced: {context_window: 32768}     # Good balance
  quality: {context_window: 65536}      # Extended for better quality
  extended: {context_window: 128000}    # Full 128K context
metadata:
  description: OpenAI GPT-4o-mini - fast, efficient, great for chat and simple tasks
  category: general
  status: stable
  release_date: '2024-07-18'
  recommended_for:
    - "Fast chat responses"
    - "Simple Q&A"
    - "Conversational AI"
    - "Classification tasks"
  not_recommended_for:
    - "Complex reasoning requiring o1/o3"
    - "Tasks requiring deep analysis"
tier: B
tier_rank: 3
resource_class:
  class: A
  vram_gb: 0.0
  throughput_tier: high
