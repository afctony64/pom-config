id: llama3.2:3b
name: Llama 3.2 3B Instruct
type: llm_model
version: 1.0.0
provider:
  name: ollama
  api_type: ollama
adapter_config:
  type: ollama
  model: llama3.2:3b-instruct-q4_K_M
  base_url: null
  base_url_env: null
parameters:
  temperature: 0.7
  max_tokens: 500
  top_p: 0.9
capabilities:
  structured_output: true
  reasoning: false
  tool_calling: false
  streaming: true
  vision: false
  function_calling: false
cost:
  per_1m_input_tokens: 0.0
  per_1m_output_tokens: 0.0
  currency: USD
  notes: Free local inference
performance:
  avg_latency_ms: 800
  context_window: 8192
  tokens_per_second: 80
backends:
  mac_metal:
    optimal_parallelism: 1
  spark_cuda:
    optimal_parallelism: 40
resource_class:
  class: A
  vram_gb: 2.0
  recommended_parallel: 40
  throughput_tier: high
metadata:
  description: Meta Llama 3.2 3B - Efficient small model with strong reasoning
  category: ultra-efficient
  status: active
