id: groq-qwen3-32b
aliases:
- groq:qwen3-32b
- qwen3-32b-groq
name: Groq Qwen3 32B
type: llm_model
version: 1.0.0
provider:
  name: groq
  api_type: chat
adapter_config:
  type: groq
  model: qwen/qwen3-32b
  base_url: https://api.groq.com/openai/v1
  base_url_env: GROQ_API_KEY
parameters:
  temperature: 0.7
  max_tokens: 4096
  top_p: 0.9
capabilities:
  structured_output: true
  reasoning: false
  tool_calling: true
  streaming: true
  vision: false
  function_calling: true
  multimodal: false
cost:
  per_1m_input_tokens: 0.29
  per_1m_output_tokens: 0.59
  currency: USD
  notes: Groq LPU inference
performance:
  avg_latency_ms: 500
  tokens_per_second: 662
  context_window: 131072

# Context variants for strategy-aware context management (cloud - can use large context)
context_variants:
  throughput: {context_window: 16384}   # Fast, cost-efficient
  balanced: {context_window: 32768}     # Good balance
  quality: {context_window: 65536}      # Extended for complex tasks
  extended: {context_window: 131072}    # Full 128K context

metadata:
  description: Qwen3 32B on Groq LPU - ultra-fast inference (~662 tok/s)
  category: reasoning
  status: stable
  release_date: '2025-04-01'
routing:
- groq
tier: S
tier_rank: 2
resource_class:
  class: C
  vram_gb: 0.0
  throughput_tier: moderate
