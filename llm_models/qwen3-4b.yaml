id: "qwen3:4b"
name: Qwen 3 4B
type: llm_model
version: "1.0.0"
provider: {name: ollama, api_type: ollama}
adapter_config: {type: ollama, model: "qwen3:4b", base_url: null, base_url_env: OLLAMA_HOST}
parameters: {temperature: 0.7, max_tokens: 1000, top_p: 0.9}
capabilities: {structured_output: true, reasoning: true, tool_calling: true, streaming: true, vision: false, function_calling: true, multimodal: false}
cost: {per_1m_input_tokens: 0.0, per_1m_output_tokens: 0.0, currency: USD, notes: "Free local"}
performance: {avg_latency_ms: 400, tokens_per_second: 100, context_window: 8192}  # Practical (theoretical: 131072)
metadata: {description: "Alibaba Qwen 3 4B - Fast reasoning", category: reasoning, status: stable, release_date: "2025-04-01", last_verified: "2025-12-05", family: qwen3, family_tier: entry, recommended_for: ["Fast reasoning", "Tool calls"], not_recommended_for: ["Complex analysis"]}
requirements: {gpu_vram_mb: 2500, system_ram_mb: 4000, cpu_cores: 2.0}
hardware_detection: {execution_mode: local_gpu, optimal_concurrency: 32, max_concurrency: 48, dgx_spark: {optimal_parallel_workers: 40, recommended_batch_size: 4, memory_usage_gb: 2.5, tokens_per_second: 100}}
resource_class: {class: A, vram_gb: 2.5, parallel_capacity_spark: 50, recommended_parallel: 40, throughput_tier: high, tokens_per_second_single: 100}
tier: C
tier_rank: 2
dimension_scores: {summarization: 65, reasoning: 72, instruction: 70, analysis: 68, coding: 75, speed: 90, context_efficiency: 85}
pom_benchmarks: {last_calibration: "2025-12-05", calibration_version: "2.0", aggregate: {avg_quality: 70, avg_latency_ms: 400, total_prompts_tested: 0}}
benchmarks: {}
