id: mistral:7b
name: Mistral 7B Instruct
type: llm_model
version: 1.0.0
provider:
  name: ollama
  api_type: ollama
adapter_config:
  type: ollama
  model: mistral:7b-instruct
  base_url: null
  base_url_env: null
parameters:
  temperature: 0.7
  max_tokens: 500
  top_p: 0.9
capabilities:
  structured_output_json_basic: true
  structured_output_json_strict: false
  structured_output_other: []
  structured_output: true
  reasoning: false
  tool_calling: false
  streaming: true
  vision: false
  function_calling: false
cost:
  per_1m_input_tokens: 0.0
  per_1m_output_tokens: 0.0
  currency: USD
  notes: Free local inference
performance:
  avg_latency_ms: 200
  tokens_per_second: 80
  context_window: 32768  # Mistral 7B supports 32K context
  backends:
    mac_metal:
      optimal_parallelism: 1
    spark_cuda:
      optimal_parallelism: 6
resource_class:
  class: B
  vram_gb: 4.0
  parallel_capacity_spark: 6
  recommended_parallel: 6
  throughput_tier: moderate

metadata:
  description: Mistral 7B Instruct - General purpose instruction-following model
  category: general
  status: stable
  release_date: "2024-01-01"
  last_verified: "2025-01-07"
  recommended_for:
    - "General instruction following"
    - "Chat and conversation"
  not_recommended_for:
    - "Complex reasoning tasks"
