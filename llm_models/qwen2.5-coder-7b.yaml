id: "qwen2.5-coder:7b"
name: Qwen 2.5 Coder 7B
type: llm_model
version: "1.0.0"
provider: {name: ollama, api_type: ollama}
adapter_config: {type: ollama, model: "qwen2.5-coder:7b", base_url: null, base_url_env: OLLAMA_HOST}
parameters: {temperature: 0.7, max_tokens: 2000, top_p: 0.9}
capabilities: {structured_output: true, reasoning: true, tool_calling: true, streaming: true, vision: false, function_calling: true, multimodal: false}
cost: {per_1m_input_tokens: 0.0, per_1m_output_tokens: 0.0, currency: USD, notes: "Free local/VastAI"}
performance: {avg_latency_ms: 800, tokens_per_second: 60, context_window: 32768}
metadata:
  description: "Alibaba Qwen 2.5 Coder 7B - Specialized for code generation"
  category: code
  status: stable
  release_date: "2025-01-15"
  last_verified: "2025-12-15"
  family: qwen2.5-coder
  family_tier: entry
  strength: coding
  recommended_for:
    - Code generation
    - Code completion
    - Technical documentation
  not_recommended_for:
    - General reasoning
    - Creative writing
requirements: {gpu_vram_mb: 5000, system_ram_mb: 8000, cpu_cores: 2.0}
hardware_detection:
  execution_mode: local_gpu
  optimal_concurrency: 16
  max_concurrency: 24
vastai_config:
  enabled: true
  endpoint_name: "vLLM-Qwen2.5-Coder-7B"
  huggingface_model: "Qwen/Qwen2.5-Coder-7B-Instruct"
  cold_workers: 0
  # NOTE: Vast.ai hosts with low disk frequently fail HF/vLLM downloads.
  disk_space_gb: 100
  gpu_requirements: "gpu_ram>=16 num_gpus=1 inet_down>100"
  template_hash: "03fba9bdccaa8ace9ad931105d8e9eb4"
  estimated_cold_start_seconds: 120
  priority: 6
resource_class: {class: B, vram_gb: 5.0, parallel_capacity_spark: 25, recommended_parallel: 20, throughput_tier: high, tokens_per_second_single: 60}
tier: B
tier_rank: 3
dimension_scores:
  summarization: 65
  reasoning: 70
  instruction: 75
  analysis: 68
  coding: 88
  speed: 80
  context_efficiency: 85
pom_benchmarks:
  last_calibration: "2025-12-15"
  calibration_version: "1.0"
  aggregate: {avg_quality: 75, avg_latency_ms: 800, total_prompts_tested: 0}
benchmarks: {}
