id: "qwen2.5:7b"
name: Qwen 2.5 7B
type: llm_model
version: "1.0.0"
provider: {name: ollama, api_type: ollama}
adapter_config: {type: ollama, model: "qwen2.5:7b", base_url: null, base_url_env: OLLAMA_HOST}
parameters: {temperature: 0.7, max_tokens: 2000, top_p: 0.9}
capabilities: {structured_output: true, reasoning: true, tool_calling: true, streaming: true, vision: false, function_calling: true, multimodal: false}
cost: {per_1m_input_tokens: 0.0, per_1m_output_tokens: 0.0, currency: USD, notes: "Free local inference"}

performance:
  avg_latency_ms: 200
  tokens_per_second: 92.6  # Mac Metal benchmark (December 2025)
  context_window: 32768
  
  # Backend-specific benchmarks (December 2025)
  backends:
    mac_metal:
      tokens_per_second: 92.6
      avg_latency_ms: 180
      optimal_parallelism: 6
      memory_bandwidth_gbs: 546
    spark_cuda:
      tokens_per_second: 19.3
      avg_latency_ms: 850
      optimal_parallelism: 4
      memory_bandwidth_gbs: 273

# Priority-based routing
routing: [mac, spark]  # Mac Metal 92.6 tok/s > Spark 19.3 tok/s
metadata:
  description: "Alibaba Qwen 2.5 7B - Balanced general purpose model"
  category: general
  status: stable
  release_date: "2025-01-15"
  last_verified: "2025-12-15"
  family: qwen2.5
  family_tier: entry
  strength: balanced
  recommended_for:
    - General tasks
    - Fast inference
    - Instruction following
  not_recommended_for:
    - Complex reasoning (use Qwen3)
requirements: {gpu_vram_mb: 5000, system_ram_mb: 8000, cpu_cores: 2.0}
hardware_detection:
  execution_mode: local_gpu
  optimal_concurrency: 16
  max_concurrency: 24
resource_class: {class: B, vram_gb: 5.0, parallel_capacity_spark: 25, recommended_parallel: 20, throughput_tier: high, tokens_per_second_single: 93}  # Mac Metal (December 2025)
tier: B
tier_rank: 2
dimension_scores:
  summarization: 72
  reasoning: 74
  instruction: 78
  analysis: 70
  coding: 72
  speed: 82
  context_efficiency: 85
pom_benchmarks:
  last_calibration: "2025-12-15"
  calibration_version: "1.0"
  aggregate: {avg_quality: 74, avg_latency_ms: 600, total_prompts_tested: 0}
benchmarks: {}
