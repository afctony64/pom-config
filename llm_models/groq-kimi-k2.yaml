id: "groq-kimi-k2"
aliases:
  - "kimi-k2"
  - "groq:kimi-k2"
name: Groq Kimi K2 Instruct
type: llm_model
version: "1.0.0"

provider:
  name: groq
  api_type: chat

adapter_config:
  type: groq
  model: moonshotai/kimi-k2-instruct
  base_url: https://api.groq.com/openai/v1
  base_url_env: GROQ_API_KEY

parameters:
  temperature: 0.7
  max_tokens: 4000
  top_p: 0.9

capabilities:
  structured_output: true
  reasoning: true
  tool_calling: true
  streaming: true
  vision: false
  function_calling: true
  multimodal: false

cost:
  per_1m_input_tokens: 0.20
  per_1m_output_tokens: 0.60
  currency: USD
  notes: "Groq LPU - Moonshot AI Kimi K2"

performance:
  avg_latency_ms: 300
  tokens_per_second: 450
  context_window: 131072

# Context variants for strategy-aware context management (Groq - fast reasoning model)
context_variants:
  throughput: {context_window: 16384}   # Fast processing
  balanced: {context_window: 32768}     # Good balance
  quality: {context_window: 65536}      # Extended for complex tasks
  extended: {context_window: 131072}    # Full 131K context

metadata:
  description: "Kimi K2 by Moonshot AI - strong reasoning and coding"
  category: reasoning
  status: stable
  release_date: "2025-06-01"
  last_verified: "2025-12-18"
  family: kimi
  family_tier: premium
  recommended_for:
    - "Complex reasoning"
    - "Coding tasks"
    - "Long context"
  not_recommended_for:
    - "Simple tasks"

requirements:
  gpu_vram_mb: 0
  system_ram_mb: 0
  cpu_cores: 0

hardware_detection:
  execution_mode: cloud

routing: [groq]

resource_class:
  class: A
  vram_gb: 0
  throughput_tier: high
  tokens_per_second_single: 450

tier: S
tier_rank: 1

dimension_scores:
  summarization: 90
  reasoning: 94
  instruction: 90
  analysis: 92
  coding: 95
  speed: 90
  context_efficiency: 95

pom_benchmarks:
  last_calibration: "2025-12-18"
  calibration_version: "2.0"
  aggregate:
    avg_quality: 92
    avg_latency_ms: 300
    total_prompts_tested: 0

benchmarks: {}
