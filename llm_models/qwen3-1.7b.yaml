id: "qwen3:1.7b"
name: Qwen 3 1.7B
type: llm_model
version: "1.0.0"
provider: {name: ollama, api_type: ollama}
adapter_config: {type: ollama, model: "qwen3:1.7b", base_url: null, base_url_env: OLLAMA_HOST}
parameters: {temperature: 0.7, max_tokens: 500, top_p: 0.9}
capabilities: {structured_output: true, reasoning: false, tool_calling: true, streaming: true, vision: false, function_calling: true, multimodal: false}
cost: {per_1m_input_tokens: 0.0, per_1m_output_tokens: 0.0, currency: USD, notes: "Free local"}
performance: {avg_latency_ms: 200, tokens_per_second: 150, context_window: 4096}  # Practical for small model

# Context variants for strategy-aware context management
context_variants:
  throughput: {context_window: 2048}   # Ultra-fast, minimal memory
  balanced: {context_window: 4096}     # Default for this model
  quality: {context_window: 8192}      # Max practical for tiny model
metadata:
  description: "Alibaba Qwen 3 1.7B - Ultra-fast tiny model for simple tasks"
  category: reasoning
  status: stable
  release_date: "2025-04-01"
  last_verified: "2025-12-15"
  family: qwen3
  family_tier: tiny
  strength: speed
  recommended_for:
    - Quick classification
    - Simple formatting
    - Tab autocomplete
    - Low-latency tasks
  not_recommended_for:
    - Complex reasoning
    - Long-form generation
    - Analysis tasks
requirements: {gpu_vram_mb: 1300, system_ram_mb: 2000, cpu_cores: 1.0}
hardware_detection:
  execution_mode: local_gpu
  optimal_concurrency: 64
  max_concurrency: 96
  dgx_spark: {optimal_parallel_workers: 80, recommended_batch_size: 8, memory_usage_gb: 1.3, tokens_per_second: 150}
resource_class: {class: A, vram_gb: 1.3, parallel_capacity_spark: 100, recommended_parallel: 80, throughput_tier: high, tokens_per_second_single: 150}
tier: D
tier_rank: 1
dimension_scores:
  summarization: 50
  reasoning: 55
  instruction: 60
  analysis: 45
  coding: 55
  speed: 98
  context_efficiency: 70
pom_benchmarks:
  last_calibration: "2025-12-15"
  calibration_version: "1.0"
  aggregate: {avg_quality: 52, avg_latency_ms: 200, total_prompts_tested: 0}
benchmarks: {}
