id: "gemma3:12b"
name: Gemma 3 12B IT-QAT
type: llm_model
version: "1.0.0"
provider:
  name: ollama
  api_type: ollama
adapter_config:
  type: ollama
  model: gemma3:12b-it-qat
  base_url: null
  base_url_env: OLLAMA_HOST
parameters:
  temperature: 0.7
  max_tokens: 2000
  top_p: 0.9
capabilities:
  structured_output: true
  reasoning: true
  tool_calling: false
  streaming: true
  vision: true
  function_calling: false
  multimodal: true
cost:
  per_1m_input_tokens: 0.0
  per_1m_output_tokens: 0.0
  currency: USD
  notes: Free local inference on DGX Spark
performance:
  backends:
    mac_metal:
      optimal_parallelism: 1  # Mac Ollama does NOT handle parallel - always use 1
    spark_cuda:
      optimal_parallelism: 12  # Spark optimal parallel setting